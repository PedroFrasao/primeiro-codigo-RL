{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "2ROu51pSfeQt"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "from IPython.display import clear_output\n",
        "env = gym.make('FrozenLake-v1')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "colunas_açoes = env.action_space.n\n",
        "linhas_estados = env.observation_space.n\n",
        "\n",
        "tabela_q = np.zeros((linhas_estados, colunas_açoes))\n",
        "print(tabela_q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUlkscHbghO_",
        "outputId": "ca5eb2d9-3ba8-4e4e-fcda-e92ba4bfe0ee"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "todas_recompensas = []\n",
        "\n",
        "num_episodios = 10000\n",
        "num_passos_por_episodio = 100\n",
        "\n",
        "taxa_de_aprendizado = 0.1\n",
        "taxa_de_desconto = 0.99\n",
        "\n",
        "taxa_exploration = 1\n",
        "max_taxa_exploration = 1\n",
        "min_taxa_exploration = 0.01\n",
        "taxa_de_decaimento_da_exploração = 0.001\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #Q-learning algoritimo\n",
        "  #primeiro for contem tudo o que acontece em um unico episodio\n",
        "for episodio in range(num_episodios):\n",
        "  estado = env.reset()\n",
        "  done = False\n",
        "  recompensas_episodio_atual = 0\n",
        "   #segundo for contem tudo o que acontece em um intervalo dos episodios episodios\n",
        "  for passo in range(num_passos_por_episodio):\n",
        "    #exploration - exploitation (Trade-off)\n",
        "    limite_taxa_exploration = random.uniform(0, 1)\n",
        "\n",
        "    if limite_taxa_exploration > taxa_exploration_epilson:\n",
        "      action = np.argmax(tabela_q[estado,:])\n",
        "\n",
        "    else:\n",
        "        action = env.action_space.sample()\n",
        "\n",
        "    #new_state, reward, done, info = env.step(action)\n",
        "    novo_estado, recompensa, done, info  = env.step(action)\n",
        "\n",
        "    #atualização da tabela Q\n",
        "    tabela_q[estado, action] = tabela_q[estado, action] * (1 - taxa_de_aprendizado) + \\\n",
        "      taxa_de_aprendizado *(recompensa + taxa_de_desconto *np.max(tabela_q[novo_estado,:]))\n",
        "\n",
        "    estado = novo_estado\n",
        "    recompensas_episodio_atual += recompensa\n",
        "\n",
        "    if done == True:\n",
        "      break\n",
        "\n",
        "\n",
        "      #taxa de decaimento de exploração\n",
        "    taxa_exploration = min_taxa_exploration + \\\n",
        "    (max_taxa_exploration - min_taxa_exploration) * np.exp(-taxa_de_decaimento_da_exploração * episodio)\n",
        "\n",
        "    todas_recompensas.append(recompensas_episodio_atual)\n",
        "\n",
        "#calcular a recompensa media de um total de 1000 episodios\n",
        "media_total_recompensas = np.array_split(np.array(todas_recompensas),num_episodios/1000)\n",
        "count = 1000\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COIPhng5kQsH",
        "outputId": "a8be57c3-377a-4d49-a1dc-a6e40a54c749"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"RECOMPENSA MEDIA DE TODOS OS EPISODIOS:\")\n",
        "for r in media_total_recompensas:\n",
        "    print(count, \": \", str(sum(r/1000)))\n",
        "    count += 1000\n",
        "\n",
        "#print atualização da tabela Q\n",
        "print(\"\\n\\n********TABELA_Q********\\n\")\n",
        "print(tabela_q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysWCmOGn2eA_",
        "outputId": "2ec29c05-c50c-4090-e3ff-3c5e975db7ea"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RECOMPENSA MEDIA DE TODOS OS EPISODIOS:\n",
            "1000 :  0.0\n",
            "2000 :  0.0\n",
            "3000 :  0.0\n",
            "4000 :  0.0\n",
            "5000 :  0.0\n",
            "6000 :  0.0\n",
            "7000 :  0.0\n",
            "8000 :  0.0\n",
            "9000 :  0.0\n",
            "10000 :  0.0\n",
            "\n",
            "\n",
            "********TABELA_Q********\n",
            "\n",
            "[[0.49260643 0.48615945 0.48231157 0.47429892]\n",
            " [0.29833063 0.3813374  0.25929804 0.45833208]\n",
            " [0.43996814 0.43827941 0.43388936 0.45536078]\n",
            " [0.23159925 0.27165119 0.3381453  0.45459809]\n",
            " [0.50323185 0.40087396 0.38688589 0.33145924]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.37896374 0.19317015 0.41374772 0.10070413]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.30539094 0.31049712 0.25382793 0.54891992]\n",
            " [0.471916   0.5981161  0.36089614 0.28801542]\n",
            " [0.57402458 0.53485211 0.35831705 0.31718365]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.40409507 0.55631676 0.71961496 0.40520944]\n",
            " [0.73107678 0.85518911 0.82210774 0.71845686]\n",
            " [0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    }
  ]
}